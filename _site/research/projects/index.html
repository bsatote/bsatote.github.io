<!doctype html>
<!--[if lt IE 7]><html class="no-js lt-ie9 lt-ie8 lt-ie7" lang="en"> <![endif]-->
<!--[if (IE 7)&!(IEMobile)]><html class="no-js lt-ie9 lt-ie8" lang="en"><![endif]-->
<!--[if (IE 8)&!(IEMobile)]><html class="no-js lt-ie9" lang="en"><![endif]-->
<!--[if gt IE 8]><!--> <html class="no-js" lang="en"><!--<![endif]-->
<head>
<meta charset="utf-8">
<title>Project Descriptions &#8211; Bhushan Atote</title>

<!--link rel="stylesheet" href="https://maxcdn.bootstrapcdn.com/bootstrap/3.3.7/css/bootstrap.min.css">
<script src="https://ajax.googleapis.com/ajax/libs/jquery/3.1.1/jquery.min.js"></script>
<script src="https://maxcdn.bootstrapcdn.com/bootstrap/3.3.7/js/bootstrap.min.js"></script-->


<meta name="keywords" content="research, satwik, kottur, cmu, graduate, iitb">



<!-- Twitter Cards -->
<meta name="twitter:title" content="Project Descriptions">

<meta name="twitter:site" content="@BhushannSAtote">
<meta name="twitter:creator" content="@BhushannSAtote">

<meta name="twitter:card" content="summary">
<meta name="twitter:image" content="https://bsatote.github.io//images/default-thumb.png">

<!-- Open Graph -->
<meta property="og:locale" content="en_US">
<meta property="og:type" content="article">
<meta property="og:title" content="Project Descriptions">

<meta property="og:url" content="https://bsatote.github.io//research/projects/">
<meta property="og:site_name" content="">

<meta property="og:image" content="https://bsatote.github.io//images/default-thumb.png">






<link rel="canonical" href="https://bsatote.github.io//research/projects/">
<link href="https://bsatote.github.io//feed.xml" type="application/atom+xml" rel="alternate" title=" Feed">

<!-- http://t.co/dKP3o1e -->
<meta name="HandheldFriendly" content="True">
<meta name="MobileOptimized" content="320">
<meta name="viewport" content="width=device-width, initial-scale=1.0">

<!-- For all browsers -->
<link rel="stylesheet" href="https://bsatote.github.io//assets/css/main.css">
<!--link rel="stylesheet" href="https://bsatote.github.io//assets/css/satwik.css"-->
<link rel="stylesheet" href="./assets/css/satwik.css">

<meta http-equiv="cleartype" content="on">

<!-- HTML5 Shiv and Media Query Support -->
<!--[if lt IE 9]>
	<script src="https://bsatote.github.io//assets/js/vendor/html5shiv.min.js"></script>
	<script src="https://bsatote.github.io//assets/js/vendor/respond.min.js"></script>
<![endif]-->

<!-- Modernizr -->
<script src="https://bsatote.github.io//assets/js/vendor/modernizr-2.7.1.custom.min.js"></script>

<link href='//fonts.googleapis.com/css?family=PT+Sans+Narrow:400,700%7CPT+Serif:400,700,400italic' rel='stylesheet' type='text/css'>

<!-- Icons -->
<!-- 16x16 -->
<link rel="shortcut icon" href="https://bsatote.github.io//images/cmu-icon.png">
<!-- 32x32 -->
<link rel="shortcut icon" href="https://bsatote.github.io//images/cmu-icon.png">
<!-- 57x57 (precomposed) for iPhone 3GS, pre-2011 iPod Touch and older Android devices -->
<link rel="apple-touch-icon-precomposed" href="https://bsatote.github.io//images/cmu-icon.png">
<!-- 72x72 (precomposed) for 1st generation iPad, iPad 2 and iPad mini -->
<link rel="apple-touch-icon-precomposed" sizes="72x72" href="https://bsatote.github.io//images/cmu-icon.png">
<!-- 114x114 (precomposed) for iPhone 4, 4S, 5 and post-2011 iPod Touch -->
<link rel="apple-touch-icon-precomposed" sizes="114x114" href="https://bsatote.github.io//images/cmu-icon.png">
<!-- 144x144 (precomposed) for iPad 3rd and 4th generation -->
<link rel="apple-touch-icon-precomposed" sizes="144x144" href="https://bsatote.github.io//images/cmu-icon.png">

</head>

<body class="page">

<!--[if lt IE 9]><div class="browser-upgrade alert alert-info">You are using an <strong>outdated</strong> browser. Please <a href="http://browsehappy.com/">upgrade your browser</a> to improve your experience.</div><![endif]-->

<div class="navigation-wrapper">
	<div class="site-name">
		<a href="https://bsatote.github.io//"></a>
	</div><!-- /.site-name -->
	<div class="top-navigation">
		<nav role="navigation" id="site-nav" class="nav">
		    <ul>
		        
				    <li><a href="/" >Home</a></li>
				
				    <li><a href="/research/" >Research</a></li>
				
				    <li><a href="/music/" >Music</a></li>
				
				    <li><a href="/reports/bhushan.pdf" >Resume</a></li>
				
				    <li><a href="/contact/" >Contact</a></li>
				
		    </ul>
		</nav>
	</div><!-- /.top-navigation -->
</div><!-- /.navigation-wrapper -->




<div id="main" role="main">
  <div class="article-author-side" id="sticky-bio">
    


<div itemscope itemtype="http://schema.org/Person">


	<img src="https://bsatote.github.io//images/bio-photo.jpg" class="bio-photo" alt="Bhushan Atote bio photo">


  <h3 itemprop="name">Bhushan Atote</h3>
  <p>PhD candidate
  <br>University of Warwick
  <br>Coventry, UK</p>
  <!--p>PhD candidate<br/>Warwick&#13;&#10;Coventry, UK</p-->
  <a href="mailto:bhushan.atote@warwick.ac.uk" class="author-social" target="_blank"><i class="fa fa-fw fa-envelope-square"></i> Email</a>
  <a href="http://twitter.com/BhushannSAtote" class="author-social" target="_blank"><i class="fa fa-fw fa-twitter-square"></i> Twitter</a>
  
  
  <a href="http://linkedin.com/in/bhushanatote" class="author-social" target="_blank"><i class="fa fa-fw fa-linkedin-square"></i> LinkedIn</a>
  
  <a href="http://instagram.com/bhushanatote" class="author-social" target="_blank"><i class="fa fa-fw fa-instagram"></i> Instagram</a>
  
  <a href="http://github.com/bsatote" class="author-social" target="_blank"><i class="fa fa-fw fa-github"></i> Github</a>
  
  
  
  
  
  
  
  
  
  
  

</div>

  </div>
  <article class="page">
    <h1>Project Descriptions</h1>
    <div class="article-wrap">
      <p>You can find descriptions of all the projects below:</p>

<section id="table-of-contents" class="toc">
  <header>
    <h3><i class="fa fa-book"></i> overview</h3>
  </header>
<div id="drawer">
    <ul id="markdown-toc">
<li><a href="#autonomous-underwater-vehicle-auv-iitb">Autonomous Underwater Vehicle (AUV-IITB)</a></li>
<li><a href="#static-vehicle-detection-and-analysis-in-aerial-imagery-using-depth">Static Vehicle Detection and Analysis in Aerial Imagery using Depth</a></li>
<li><a href="#human-activity-recognition">Human Activity Recognition</a></li>
<li><a href="#parallel-simulation-of-verilog-hdl-designs">Parallel Simulation of Verilog HDL designs</a></li>
</ul>
  </div>
</section>
<!-- /#table-of-contents -->

<h3 id="autonomous-underwater-vehicle-auv-iitb">Autonomous Underwater Vehicle (AUV-IITB)</h3>
<p><em>AUVSI and ONR’’s International Robosub Competition, San Diego, USA</em><br />
<em>Vision (Spring 2012 - Spring 2013)</em><br />
Guides: Dr. Hemendra Arya and Dr. Leena Vachhani<br />
[<a href="/reports/IIT_Bombay_Journal_Paper_2012.pdf">Journal Paper (2012)</a>] [<a href="/reports/IIT_Bombay_Journal_Paper_2013.pdf">Journal Paper (2013)</a>]</p>

<p>Designing and developing an unmanned autonomous underwater vehicle (AUV) that localizes itself and performs realistic missions based on feedback from visual, inertial, acoustic and depth sensors using thrusters and pneumatic actuators. Matsya (sanskrit word for fish) is the AUV from IIT Bombay to participate in the International Robosub competition, San Diego which sees teams of different universities from countries all over the world.</p>

<figure class="half">
    <a href="/images/auv-machine1.jpg"><img src="/images/auv-machine1.jpg" /></a>
    <a href="/images/auv-machine2.jpg"><img src="/images/auv-machine2.jpg" /></a>
    <figcaption>Matsya 2.0 (2013) (left), Matysa 1.0 (2012) (right).</figcaption>
</figure>
<p><br /></p>
<figure align="center">
    <a href="/images/auv-team.jpg"><img src="/images/auv-team.jpg" /></a>
    <figcaption>Team (2013) at SSC Transdec, San Diego.</figcaption>
</figure>
<p><br /></p>

<p>More information about the competition can be found <a href="http://www.auvsifoundation.org/foundation/competitions/robosub/">here</a>.
Details about the AUV IITB team are present <a href="http://auv-iitb.org/">here</a>.</p>

<p>Machine vision for Autonomous Underwater Vehicles poses three important challenges:</p>

<ol>
  <li>Degraded image quality due to the medium—Low visibility, color casting (blue or green), poor constrast, varying illuminations, brightness artifacts and blurring are of primary concern. Hence, pre-processing of images to correct these degradations is necessary to ensure robust detection in later stages of analysis.</li>
  <li>Limited on-board computational capacity—Since the vehicle has a centralized processor and a plethora of sensors and other peripherals, power management is of utmost importance. Such a conservation lays a direct contraint on the amount of computing available for the current mission. This eliminates the scope for using processor-intensive techniques thereby increasing the challenge further.</li>
  <li>Real-time requirement for navigation of the machine—The two on-board cameras are an importance source of feedback for the vehicle. For a reliable navigation and actuator control, detection algorithms have an additional condition of real-time execution.</li>
</ol>

<p>To tackle the above problems, we devised adaptive identification and correction of color casts in images, edge-saliency based color segmentation and adaptive enhancement based on corrected color cast, amongst other techniques formulated after thorough literature survey.</p>

<h4 id="references">References:</h4>
<ol class="references">
<li>Zuiderveld, Karel. Constrast Limited Adaptive Histogram Equalization.</li>
<li>P. Felzenszwalb, D. Huttenlocher. Efficient Graph-based Image Segmentation.</li>
<li>Finlayson, G.D., E. Trezzi. Shades of Gray and Color Constancy.</li>
<li> Cosmin Ancuti, Codruta Orniana Ancuti,Tom Haber, Philippe Bekaert. Enhancing underwater images and vides by fusion. <i>Computer Vision and Pattern Recognition (CVPR), 2012</i></li>
</ol>
<p>[<a href="/research/projects/">TOP</a>] [<a href="/research/#autonomous-underwater-vehicle-auv-iitb">BACK</a>]</p>

<hr />

<h3 id="static-vehicle-detection-and-analysis-in-aerial-imagery-using-depth">Static Vehicle Detection and Analysis in Aerial Imagery using Depth</h3>
<p><em>Internship at <a href="http://iris.usc.edu/iris.html">IRIS</a>, University of Southern California, Summer 2013</em><br />
Guide: Prof. Gerard Medioni<br />
[<a href="/reports/VehicleDetection-Report.pdf">Report</a>] [<a href="/reports/VehicleDetection-Poster.pdf">Poster</a>]</p>

<p>Vehicle detection and identification in urban scenarios has many civilian, security and surveillance application. 
The easy availability of aerial images along with its advantage of spanning wide areas due to large field of view, makes the problem of such identification in aerial images interesting. 
Primarily, this work proposes a detection algorithm using depth information for identification of static vehicles, particularly in parking lots. 
The scene depth is obtained from Digital Surface Model (DSM) of the urban landscape. 
Finally, the dependence of performance on the 3D model parameters is analyzed.</p>

<figure class="half">
    <a href="/images/vehicle-orig-image.jpg"><img src="/images/vehicle-orig-image.jpg" /></a>
    <a href="/images/vehicle-detect-image.jpg"><img src="/images/vehicle-detect-image.jpg" /></a>
    <figcaption>Original aerial image (left), detections based on depth (right).</figcaption>
</figure>
<p><br /></p>

<p>From the approaches proposed by various researchers in the community, <strong>[1, 2, 3, 4]</strong> are closely related to the current work.
<strong>[1]</strong> provides the 3D model of the landscape used in the proposed algorithm. 
Depth features have been explored for vehicle identification by B. Yang et al. in <strong>[2]</strong>. However, <strong>[2]</strong> uses LIDAR data unlike <strong>[1]</strong> which uses stream of aerial images for estimating scene depth.</p>

<p>In this work, depth features are obtained from <strong>[1]</strong>, which itself is a novel technique to simultaneously solve for camera positions and dense depth estimation. For a given image, height is backprojected onto it using the 3D model. Haar-like features are used for a small portion of the image using sliding window, to estimate the presence or absence of a vehicle. In order to improve the accuracy, validation is incorporated using the edge-saliency of wire frame model as proposed in <b>[4]</b>. To understand the behavior of the system better, analysis of the performance is performed by varying the parameters of optical flow (regularization term, number of iterations, etc.) used in 3D model generation. A high negative correlation between the regularization term and accuracy of the system can be clearly concluded. This analysis can be used to better the overall system thereby an indicative of the scope for improvement.</p>

<h4 id="references-1">References:</h4>
<ol>
  <li>Zhouliang Kang, Gerard Medioni. 3D Urban Reconstruction from Wide Area Aerial Surveillance Video. <em>Workshop on Applications for Aerial Video Exploitation (WAVE), 2015</em>.
[<a href="http://www-scf.usc.edu/~zkang/wave2015.pdf">Paper</a>]</li>
  <li>Bo Yang, Pramod Sharma, Ram Nevatia. Vehicle Detection from Low Quality Aerial LIDAR Data. [<a href="http://citeseerx.ist.psu.edu/viewdoc/summary?doi=10.1.1.309.8325">Paper</a>]</li>
  <li>Y. Lin H. Liao and G. Medioni. Aerial 3D reconstruction with line-constrained dynamic programming. <i>In ICCV,2011.</i> [<a href="http://citeseerx.ist.psu.edu/viewdoc/summary?doi=10.1.1.309.9111">Paper</a>]</li>
  <li>Stefan Hinz. Integrating local and global features for vehicle detection in high resolution aerial imagery. <i>ISPRS Archives,2003, XXXIV(3/W8)</i> [<a href="http://citeseerx.ist.psu.edu/viewdoc/summary?doi=10.1.1.97.7312">Paper</a>]</li>
</ol>

<p>[<a href="/research/projects/">TOP</a>] [<a href="/research/#static-vehicle-detection-and-analysis-in-aerial-imagery-using-depth">BACK</a>]</p>

<hr />

<h3 id="human-activity-recognition">Human Activity Recognition</h3>
<p><em>B.Tech project-I, IIT Bombay, Fall 2013</em><br />
Guide: Prof. Subhasis Chaudhuri<br />
[<a href="/reports/HumanActivity-Report.pdf">Report</a>] [<a href="HumanActivity-Poster.pdf">Poster</a>]</p>

<p>The need for security and surveillance is always on the rise. This work is an attempt to address this problem in a social gathering using a single, calibrated camera. To begin with, it is a survey of existing methods—studying the advantages and suitability to the problem at hand. Next, a pipeline of approach is proposed similar to the work of Neha et al. in <b>[2]</b>. Finally, suitable improvements are suggested for the scenario considered.</p>

<figure align="center">
    <a href="/images/human-pipeline.jpg"><img src="/images/human-pipeline.jpg" /></a>
    <figcaption>Proposed Pipeline.</figcaption>
</figure>
<p><br /></p>

<p>Human Activity is one of the most actively pursued topic owing to its wide range of applications. It has been studied mainly under two approaches—holistic and reductionist. The former considers the crowd as a single entity while the latter models individuals seperately and studies their interaction. <b>[1]</b> and <b>[2]</b> provide the respective examples. This work falls under the latter category.</p>

<figure class="half">
    <a href="/images/human-dpm.jpg"><img src="/images/human-dpm.jpg" /></a>
    <a href="/images/human-track.jpg"><img src="/images/human-track.jpg" /></a>
    <figcaption>Results of DPM (left), tracking feature points (right).</figcaption>
</figure>
<p><br /></p>

<p>Following a pipeline similar to <b>[2]</b>, frames from the calibrated camera are used to detect humans. Deformable part models (<b>[5]</b>) is employed for the first stage of detection. Due to high computation time, only intermittent frames are used to identify humans and corresponding parts. These detected parts form the feature points and are tracked by the Lucas-Kanade algorithm for remaining frames. This reduces the overall complexity and makes the execution real-time. The feature points on the image plane (2D) are converted to 3D points in world co-ordinates (classically known as 2.5D) using average height plane assumption. Finally, linear cylic pursuit model (LCP) is employed to predict the short-term trajectories of these points for further analysis. Finer details can be found in the report.</p>

<h4 id="references-2">References:</h4>
<ol class="references">
<li>Viswanthan Srikrishnan and Subhasis Chaudhuri. Crowd motion analysis using linear cyclic pursuit.<i>In Pattern Recognition (ICPR), 2010 20th International Conference on, pages 3340–3343. IEEE, 2010.</i></li>
<li>Neha Bhargava, Subhasis Chaudhuri and Guna Seetharaman. Linear cyclic pursuit based prediction of personal space violation in surveillance video. <i>Applied Imagery Pattern Recognition Workshop, 2013.</i></li>
<li>Arpita Sinha. Multi-agent consensus using generalized cyclic pursuit strategies. 2009.</li>
<li>Carlo Tomasi and Takeo Kanade. Detection and tracking of point features. <i>International Journal of Computer Vision, 1991.</i></li>
<li>P. F. Felzenszwalb, R. B. Girshick, D. McAllester, and D. Ramanan. Object detection with discriminatively trained part based models. <i>IEEE Transactions on Pattern Analysis and Machine Intelligence, 32(9):1627–1645, 2010.</i></li>
</ol>
<p>[<a href="/research/projects/">TOP</a>] [<a href="/research/#human-activity-recognition">BACK</a>]</p>

<hr />

<h3 id="parallel-simulation-of-verilog-hdl-designs">Parallel Simulation of Verilog HDL designs</h3>
<p><em>Internship, IIT Bombay, Summer 2012</em><br />
Guide: Prof. Sachin Patkar</p>

<p>Digital designs, before synthesis, are simulated on a computer platform to test their efficiency. Maximizing the performance and minimizing the overheads is, therefore, a vital area of research. The main focus of this work is to parallelize the simulation of single clock structural/behavior hardware designs without any time or resource conflict. Thus, resulting in a multi-fold in reduction in execution time.</p>

<figure class="half">
    <a href="/images/digital-code.jpg"><img src="/images/digital-code.jpg" /></a>
    <a href="/images/digital-graph.jpg"><img src="/images/digital-graph.jpg" /></a>
    <figcaption>Sample Verilog design (left), equivalent graph representation (right).</figcaption>
</figure>
<p><br /></p>

<p>Due to advancements in the multi-core precessors, it is possible to simulate parallelizable designs faster. The flow of the work is briefly given below:</p>
<ol class="proj-points">
<li>A given hardware design is converted into a standard XML structure. This allows the feasibility of using any description language (Verilog, in this case) for multi-platform compatibility.</li>
<li>This XML structure can be parsed in any high level language (Python) using standard libraries.</li>
<li>The design is systematically analyzed in the high level language to find functionally independent units.</li>
<li>These independent components are launched as seperate threads on a multi-core platform resulting in an overall reduction in time of simulation.</li>
</ol>

<p>I have been awarded <strong>Undergraduate Research Award</strong> (URA 01) for contribution to research at IIT Bombay for this work.
Since this work has been done in close association with a graduate student, most of the implementation details can be found in his thesis report <a href="/reports/Digital-Reference.pdf">here</a>.<br />
[<a href="/research/projects/">TOP</a>] [<a href="/research/#parallel-simulation-of-verilog-hdl-designs">BACK</a>]</p>

      
        <hr />
      
    </div><!-- /.article-wrap -->
    
  </article>
</div><!-- /#index -->

<div class="footer-wrap">
  <footer>
    

<span>&copy; 2023 Bhushan Atote. Powered by <a href="http://jekyllrb.com" rel="nofollow">Jekyll</a> using the <a href="http://mademistakes.com/minimal-mistakes/" rel="nofollow">Minimal Mistakes</a> theme.</span>

  </footer>
</div><!-- /.footer-wrap -->

<script src="//ajax.googleapis.com/ajax/libs/jquery/1.9.1/jquery.min.js"></script>
<script>window.jQuery || document.write('<script src="https://bsatote.github.io//assets/js/vendor/jquery-1.9.1.min.js"><\/script>')</script>
<script src="https://bsatote.github.io//assets/js/scripts.min.js"></script>



<script type="text/javascript">
    // Open all external links in new tab
    var links = document.links;
    for (var i = 0, linksLength = links.length; i < linksLength; i++) {
        if (links[i].hostname != window.location.hostname) {
            links[i].target = '_blank';
        } 
    }

/*var elementPosition = $('#sticky-bio').offset();

$(window).scroll(function(){

    $('#sticky-bio').css({'position':'fixed','top':'0'});
    $('#sticky-bio').css({'min-height':'100%'});
    /*if($(window).scrollTop() > elementPosition.top){
        $('#sticky-bio').css({'position':'fixed','top':'1'});
        $('.bg1 h2').css({'margin-top':'232px'});
    } else {
        $('#sticky-bio').css({'position':'static'});
    }
});*/
</script>


</body>
</html>
